{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Feb/2024 09:21:18] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000210CF108310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 134ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Feb/2024 09:21:25] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Feb/2024 09:21:25] \"GET /static/images/input/test1_MOD.jpg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Feb/2024 09:21:25] \"GET /static/images/grad/grad_cam_result.jpg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load your machine learning model\n",
    "model_path = \"C:/Users/mayan/Desktop/Projects/AI ML/Alzheimer's Detection/final_model_02.h5\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Allow files with extension png, jpg, and jpeg\n",
    "ALLOWED_EXT = {'jpg', 'jpeg', 'png'}\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXT\n",
    "\n",
    "# Function to generate Grad-CAM dynamically\n",
    "def generate_grad_cam(img_array, class_index, layer_name):\n",
    "    grad_cam_model = tf.keras.models.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer = grad_cam_model.get_layer(layer_name)\n",
    "        iterate_model = tf.keras.models.Model([grad_cam_model.inputs], [grad_cam_model.output, last_conv_layer.output])\n",
    "        model_out, last_conv_layer_out = iterate_model(img_array)\n",
    "        class_out = model_out[:, class_index]\n",
    "\n",
    "    grads = tape.gradient(class_out, last_conv_layer_out)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_out[0]\n",
    "\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    \n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Function to overlay Grad-CAM on the original image\n",
    "def overlay_grad_cam(img_path, heatmap):\n",
    "    img = cv2.imread(img_path)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "    grad_path = 'static/images/grad/grad_cam_result.jpg'\n",
    "    cv2.imwrite(grad_path, superimposed_img)\n",
    "\n",
    "    return grad_path\n",
    "\n",
    "# Function to load and prepare the image in the right shape\n",
    "def read_image(filename):\n",
    "    img = tf.keras.preprocessing.image.load_img(filename, target_size=(150, 150))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "@app.route('/')\n",
    "def index_view():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        if file and allowed_file(file.filename):  # Checking file format\n",
    "            filename = file.filename\n",
    "            file_path = os.path.join('static/images/input', filename)\n",
    "            file.save(file_path)\n",
    "            img = read_image(file_path)  # Preprocessing method\n",
    "            class_prediction = model.predict(img)\n",
    "            confidence = np.max(class_prediction) * 100\n",
    "            classes_x = np.argmax(class_prediction, axis=1)\n",
    "            stages = [\"Mild Demented\", \"Moderate Demented\", \"Non Demented\", \"Very Mild Demented\"]\n",
    "            stage = stages[classes_x[0]]\n",
    "            \n",
    "            # Generate Grad-CAM dynamically\n",
    "            layer_name = 'conv2d_2'\n",
    "            heatmap = generate_grad_cam(img, classes_x[0], layer_name)\n",
    "            \n",
    "            # Overlay Grad-CAM on the original image\n",
    "            grad_path = overlay_grad_cam(file_path, heatmap)\n",
    "            \n",
    "            return render_template('predict.html', stage=stage, prob=confidence, user_image=file_path, grad_image=grad_path)\n",
    "        else:\n",
    "            return \"Unable to read the file. Please check file extension\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False, port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
